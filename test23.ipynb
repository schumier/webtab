{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1343a6-1f56-4052-9ebc-643385316018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned JSON saved to cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read potentially malformed JSON from a file\n",
    "with open(\"D:\\\\Project\\\\pbix\\\\Human Resources Sample PBIX\\\\Report\\\\Layout\", 'r') as f:\n",
    "    raw = f.read()\n",
    "\n",
    "# Remove null bytes if present\n",
    "raw = raw.replace('\\x00', '')\n",
    "\n",
    "# Try to parse JSON safely\n",
    "try:\n",
    "    data = json.loads(raw)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")\n",
    "    # Optionally, handle or repair the JSON here\n",
    "    # For demo purposes, exit if error\n",
    "    data = None\n",
    "\n",
    "# If parsing succeeded, save cleaned JSON to a new file\n",
    "if data is not None:\n",
    "    with open(\"D:\\\\Project\\\\pbix\\\\data.json\", 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(\"Cleaned JSON saved to cleaned.json\")\n",
    "else:\n",
    "    print(\"Could not parse JSON after cleanup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned JSON saved to cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read raw content from input.json\n",
    "with open(\"D:\\\\Project\\\\pbix\\\\Human Resources Sample PBIX\\\\Report\\\\Layout\", 'r') as f:\n",
    "    raw = f.read().replace('\\x00', '').strip()\n",
    "\n",
    "# First decode: Remove outer quotes if needed\n",
    "if raw.startswith('\"') and raw.endswith('\"'):\n",
    "    # Unescape and decode the string inside the quotes\n",
    "    intermediate = json.loads(raw)\n",
    "else:\n",
    "    intermediate = raw\n",
    "\n",
    "# Second decode: Convert to Python dict\n",
    "if isinstance(intermediate, str):\n",
    "    try:\n",
    "        data = json.loads(intermediate)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: {e}\")\n",
    "        data = None\n",
    "else:\n",
    "    data = intermediate\n",
    "\n",
    "# Save cleaned JSON to cleaned.json\n",
    "if data is not None:\n",
    "    with open(\"D:\\\\Project\\\\pbix\\\\data.json\", 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(\"Cleaned JSON saved to cleaned.json\")\n",
    "else:\n",
    "    print(\"Could not parse JSON after cleanup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile=\"D:\\\\Project\\\\pbix\\\\Human Resources Sample PBIX\\\\Report\\\\Layout\"\n",
    "outfile=\"D:\\\\Project\\\\pbix\\\\data2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned JSON saved to cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_content(raw):\n",
    "    cleaned = raw.replace('\\x00', '').strip()\n",
    "    try:\n",
    "        first = json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "    if isinstance(first, str):\n",
    "        try:\n",
    "            second = json.loads(first)\n",
    "            return second\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    else:\n",
    "        return first\n",
    "\n",
    "# Safest way: read as bytes, decode with replacement for errors\n",
    "with open(inputfile, 'rb') as f:\n",
    "    raw_bytes = f.read()\n",
    "raw = raw_bytes.decode('utf-8', errors='replace')\n",
    "\n",
    "parsed = parse_json_content(raw)\n",
    "\n",
    "if parsed is not None:\n",
    "    with open(outfile, 'w', encoding='utf-8') as f:\n",
    "        json.dump(parsed, f, indent=4)\n",
    "    print(\"Cleaned JSON saved to cleaned.json\")\n",
    "else:\n",
    "    print(\"Could not parse JSON after cleanup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "# import json\n",
    "\n",
    "def unzip_pbix(pbix_path):\n",
    "    \"\"\"\n",
    "    Unzips a Power BI .pbix file to a temporary directory.\n",
    "\n",
    "    Args:\n",
    "        pbix_path (str): Path to the .pbix file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the temporary directory containing the extracted files.\n",
    "    \"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    with zipfile.ZipFile(pbix_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "    return temp_dir\n",
    "\n",
    "def find_layout_json(unzipped_dir):\n",
    "    \"\"\"\n",
    "    Finds the Layout file in the unzipped PBIX directory.\n",
    "\n",
    "    Args:\n",
    "        unzipped_dir (str): Path to the directory with PBIX contents.\n",
    "\n",
    "    Returns:\n",
    "        str: Full path to the Layout JSON file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no Layout file is found.\n",
    "    \"\"\"\n",
    "    # Usually named \"Layout\" or \"Layout.json\"\n",
    "    for fname in os.listdir(unzipped_dir):\n",
    "        if fname.lower().startswith(\"layout\"):\n",
    "            layout_path = os.path.join(unzipped_dir, fname)\n",
    "            return layout_path\n",
    "    raise FileNotFoundError(\"Layout JSON not found in PBIX contents.\")\n",
    "\n",
    "def read_layout_json(layout_path):\n",
    "    \"\"\"\n",
    "    Reads and parses the Layout JSON file from PBIX contents.\n",
    "\n",
    "    Args:\n",
    "        layout_path (str): Path to the Layout JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed JSON content of the Layout file.\n",
    "    \"\"\"\n",
    "    with open(layout_path, 'rb') as f:\n",
    "        raw_bytes = f.read()\n",
    "    raw_str = raw_bytes.decode('utf-8', errors='replace').replace('\\x00', '').strip()\n",
    "    return json.loads(raw_str)\n",
    "\n",
    "def extract_alias_map(proto_query):\n",
    "    alias_map = {}\n",
    "    from_list = proto_query.get('From', [])\n",
    "    for entry in from_list:\n",
    "        alias = entry.get('Name')\n",
    "        entity = entry.get('Entity')\n",
    "        if alias and entity:\n",
    "            alias_map[alias] = entity\n",
    "    return alias_map\n",
    "\n",
    "def extract_fields(selects, alias_map):\n",
    "    columns = []\n",
    "    measures = []\n",
    "    tables = set()\n",
    "    if not isinstance(selects, list):\n",
    "        return columns, measures, tables\n",
    "    for sel in selects:\n",
    "        # Column reference\n",
    "        if 'Column' in sel:\n",
    "            col = sel['Column']\n",
    "            source = None\n",
    "            if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                source = col['Expression']['SourceRef'].get('Source')\n",
    "            column = col.get('Property')\n",
    "            full_table = alias_map.get(source, source)\n",
    "            if full_table and column:\n",
    "                columns.append(f\"{full_table}.{column}\")\n",
    "                tables.add(full_table)\n",
    "        # Measure reference\n",
    "        if 'Measure' in sel:\n",
    "            meas = sel['Measure']\n",
    "            source = None\n",
    "            if 'Expression' in meas and 'SourceRef' in meas['Expression']:\n",
    "                source = meas['Expression']['SourceRef'].get('Source')\n",
    "            measure = meas.get('Property')\n",
    "            full_table = alias_map.get(source, source)\n",
    "            if full_table and measure:\n",
    "                measures.append(f\"{full_table}.{measure}\")\n",
    "                tables.add(full_table)\n",
    "        # Aggregation reference\n",
    "        if 'Aggregation' in sel:\n",
    "            agg = sel['Aggregation']\n",
    "            function_map = {\n",
    "                0: 'Sum', 1: 'Count', 2: 'Min', 3: 'Max', 4: 'Average', 5: 'DistinctCount'\n",
    "            }\n",
    "            func_name = function_map.get(agg.get('Function'), 'Aggregation')\n",
    "            agg_expr = agg.get('Expression', {})\n",
    "            if 'Column' in agg_expr:\n",
    "                col = agg_expr['Column']\n",
    "                source = None\n",
    "                if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                    source = col['Expression']['SourceRef'].get('Source')\n",
    "                column = col.get('Property')\n",
    "                full_table = alias_map.get(source, source)\n",
    "                if full_table and column:\n",
    "                    measures.append(f\"{func_name}({full_table}.{column})\")\n",
    "                    tables.add(full_table)\n",
    "    return columns, measures, tables\n",
    "\n",
    "def extract_filter_columns(filters_json, alias_map):\n",
    "    filter_columns = []\n",
    "    if not filters_json:\n",
    "        return filter_columns\n",
    "    try:\n",
    "        filters = json.loads(filters_json)\n",
    "    except Exception:\n",
    "        return filter_columns\n",
    "    for f in filters:\n",
    "        expr = f.get('expression', {})\n",
    "        # Only handle column filters\n",
    "        if 'Column' in expr:\n",
    "            col = expr['Column']\n",
    "            entity = None\n",
    "            if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                entity = col['Expression']['SourceRef'].get('Entity')\n",
    "            elif 'SourceRef' in col:\n",
    "                entity = col['SourceRef'].get('Entity')\n",
    "            column = col.get('Property')\n",
    "            if not entity:\n",
    "                # Try to get Source and map to Entity\n",
    "                source = None\n",
    "                if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                    source = col['Expression']['SourceRef'].get('Source')\n",
    "                elif 'SourceRef' in col:\n",
    "                    source = col['SourceRef'].get('Source')\n",
    "                entity = alias_map.get(source, source)\n",
    "            if entity and column:\n",
    "                filter_columns.append(f\"{entity}.{column}\")\n",
    "    return filter_columns\n",
    "\n",
    "def extract_visuals_from_section(section):\n",
    "    results = []\n",
    "    # Section-level filters\n",
    "    section_filters = section.get('filters')\n",
    "    # Try to get alias map from first visual (if any)\n",
    "    alias_map = {}\n",
    "    if section.get('visualContainers'):\n",
    "        first_visual = section['visualContainers'][0]\n",
    "        config_str = first_visual.get('config')\n",
    "        try:\n",
    "            config = json.loads(config_str)\n",
    "            proto_query = config.get('singleVisual', {}).get('prototypeQuery', {})\n",
    "            alias_map = extract_alias_map(proto_query)\n",
    "        except Exception:\n",
    "            pass\n",
    "    section_filter_columns = extract_filter_columns(section_filters, alias_map)\n",
    "    for idx, visual in enumerate(section.get('visualContainers', [])):\n",
    "        config_str = visual.get('config')\n",
    "        try:\n",
    "            config = json.loads(config_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error decoding config for visual {idx}: {e}\")\n",
    "            continue\n",
    "        visual_type = config.get('singleVisual', {}).get('visualType')\n",
    "        proto_query = config.get('singleVisual', {}).get('prototypeQuery', {})\n",
    "        local_alias_map = extract_alias_map(proto_query)\n",
    "        # Prefer local alias map, fallback to section alias map\n",
    "        alias_map_used = local_alias_map if local_alias_map else alias_map\n",
    "        selects = proto_query.get('Select', [])\n",
    "        columns, measures, tables = extract_fields(selects, alias_map_used)\n",
    "        # Visual-level filters\n",
    "        visual_filters = visual.get('filters')\n",
    "        visual_filter_columns = extract_filter_columns(visual_filters, alias_map_used)\n",
    "        # Combine section and visual filters\n",
    "        combined_filters = sorted(list(set(section_filter_columns + visual_filter_columns)))\n",
    "        results.append({\n",
    "            'visual_idx': idx,\n",
    "            'visualType': visual_type,\n",
    "            'tables': sorted(list(tables)),\n",
    "            'columns': sorted(columns),\n",
    "            'measures': sorted(measures),\n",
    "            'filters': combined_filters\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def main(layout_path):\n",
    "    with open(layout_path, 'rb') as f:\n",
    "        raw_bytes = f.read()\n",
    "    raw = raw_bytes.decode('utf-8', errors='replace').replace('\\x00', '').strip()\n",
    "    layout = json.loads(raw)\n",
    "    for section in layout.get('sections', []):\n",
    "        print(f\"=== Section: {section.get('name')} ('{section.get('displayName')}') ===\")\n",
    "        visuals = extract_visuals_from_section(section)\n",
    "        for visual in visuals:\n",
    "            print(f\"--- Visualization {visual['visual_idx']} ---\")\n",
    "            print(f\"Type: {visual['visualType']}\")\n",
    "            print(f\"Tables: {visual['tables']}\")\n",
    "            print(f\"Columns: {visual['columns']}\")\n",
    "            print(f\"Measures: {visual['measures']}\")\n",
    "            print(f\"Filters: {visual['filters']}\")\n",
    "            print()\n",
    "\n",
    "def visuals_to_dataframe(visuals):\n",
    "    # Each cell as comma-separated string for tables/columns/measures/filters\n",
    "    df = pd.DataFrame([{\n",
    "        'Section': visual.get('section', ''),  # Add section if available\n",
    "        'Visual Index': visual['visual_idx'],\n",
    "        'Type': visual['visualType'],\n",
    "        'Tables': ', '.join(visual['tables']),\n",
    "        'Columns': ', '.join(visual['columns']),\n",
    "        'Measures': ', '.join(visual['measures']),\n",
    "        'Filters': ', '.join(visual.get('filters', [])),\n",
    "    } for visual in visuals])\n",
    "    return df\n",
    "\n",
    "def main2(layout_path):\n",
    "    with open(layout_path, 'rb') as f:\n",
    "        raw_bytes = f.read()\n",
    "    raw = raw_bytes.decode('utf-8', errors='replace').replace('\\x00', '').strip()\n",
    "    layout = json.loads(raw)\n",
    "    for section in layout.get('sections', []):\n",
    "        print(f\"=== Section: {section.get('name')} ('{section.get('displayName')}') ===\")\n",
    "        visuals = extract_visuals_from_section(section)\n",
    "        df = visuals_to_dataframe(visuals)\n",
    "        print(df)\n",
    "        # for visual in visuals:\n",
    "        #     print(f\"--- Visualization {visual['visual_idx']} ---\")\n",
    "        #     print(f\"Type: {visual['visualType']}\")\n",
    "        #     print(f\"Tables: {visual['tables']}\")\n",
    "        #     print(f\"Columns: {visual['columns']}\")\n",
    "        #     print(f\"Measures: {visual['measures']}\")\n",
    "        #     print(f\"Filters: {visual['filters']}\")\n",
    "        #     print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Section: ReportSection1 ('Info') ===\n",
      "  Section  Visual Index     Type Tables Columns Measures Filters\n",
      "0                     0    image                                \n",
      "1                     1  textbox                                \n",
      "=== Section: ReportSection2 ('New Hires') ===\n",
      "  Section  Visual Index                           Type  \\\n",
      "0                     0                        textbox   \n",
      "1                     1                      lineChart   \n",
      "2                     2  lineClusteredColumnComboChart   \n",
      "3                     3                       pieChart   \n",
      "4                     4                 waterfallChart   \n",
      "5                     5                        textbox   \n",
      "6                     6    lineStackedColumnComboChart   \n",
      "7                     7                        textbox   \n",
      "8                     8                        textbox   \n",
      "\n",
      "                    Tables                                Columns  \\\n",
      "0                                                                   \n",
      "1       Date, Employee, FP                  Date.Month, FP.FPDesc   \n",
      "2           Date, Employee                             Date.Month   \n",
      "3         Employee, Gender                          Gender.Gender   \n",
      "4       AgeGroup, Employee                      AgeGroup.AgeGroup   \n",
      "5                                                                   \n",
      "6  BU, Employee, Ethnicity  BU.Region, BU.VP, Ethnicity.Ethnicity   \n",
      "7                                                                   \n",
      "8                                                                   \n",
      "\n",
      "                                            Measures  \\\n",
      "0                                                      \n",
      "1                                 Employee.New Hires   \n",
      "2  Employee.Actives YoY % Change, Employee.New Hi...   \n",
      "3                                 Employee.New Hires   \n",
      "4                                 Employee.New Hires   \n",
      "5                                                      \n",
      "6               Employee.Actives, Employee.New Hires   \n",
      "7                                                      \n",
      "8                                                      \n",
      "\n",
      "                                             Filters  \n",
      "0  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "1  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "2  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "3  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "4  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "5  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "6  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "7  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "8  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "=== Section: ReportSection3 ('Actives and Separations') ===\n",
      "   Section  Visual Index                           Type  \\\n",
      "0                      0                        textbox   \n",
      "1                      1  lineClusteredColumnComboChart   \n",
      "2                      2                       pieChart   \n",
      "3                      3                       pieChart   \n",
      "4                      4                 waterfallChart   \n",
      "5                      5                        textbox   \n",
      "6                      6  lineClusteredColumnComboChart   \n",
      "7                      7                       barChart   \n",
      "8                      8                        textbox   \n",
      "9                      9                      lineChart   \n",
      "10                    10                      lineChart   \n",
      "\n",
      "                        Tables                            Columns  \\\n",
      "0                                                                   \n",
      "1           BU, Date, Employee       BU.Region, BU.VP, Date.Month   \n",
      "2             Employee, Gender                      Gender.Gender   \n",
      "3           AgeGroup, Employee                  AgeGroup.AgeGroup   \n",
      "4                 BU, Employee                   BU.Region, BU.VP   \n",
      "5                                                                   \n",
      "6           BU, Date, Employee       BU.Region, BU.VP, Date.Month   \n",
      "7   Employee, SeparationReason  SeparationReason.SeparationReason   \n",
      "8                                                                   \n",
      "9               Date, Employee                         Date.Month   \n",
      "10              Date, Employee                         Date.Month   \n",
      "\n",
      "                                             Measures  \\\n",
      "0                                                       \n",
      "1   Employee.Actives, Employee.Actives SPLY, Emplo...   \n",
      "2                                    Employee.Actives   \n",
      "3                                    Employee.Actives   \n",
      "4                            Employee.Actives YoY Var   \n",
      "5                                                       \n",
      "6   Employee.Actives YoY % Change, Employee.Seps, ...   \n",
      "7                                       Employee.Seps   \n",
      "8                                                       \n",
      "9                   Employee.Seps, Employee.Seps SPLY   \n",
      "10                  Employee.Seps, Employee.Seps SPLY   \n",
      "\n",
      "                                              Filters  \n",
      "0   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "1   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "2   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "3   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "4   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "5   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "6   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "7   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "8   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "9   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "10  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "=== Section: ReportSection ('Bad Hires') ===\n",
      "  Section  Visual Index            Type                    Tables  \\\n",
      "0                     0         textbox                             \n",
      "1                     1      donutChart          Employee, Gender   \n",
      "2                     2       lineChart  AgeGroup, Date, Employee   \n",
      "3                     3     columnChart   BU, Employee, Ethnicity   \n",
      "4                     4         textbox                             \n",
      "5                     5  waterfallChart        AgeGroup, Employee   \n",
      "6                     6          slicer                        BU   \n",
      "7                     7         textbox                             \n",
      "\n",
      "                                 Columns                         Measures  \\\n",
      "0                                                                           \n",
      "1                          Gender.Gender           Sum(Employee.BadHires)   \n",
      "2          AgeGroup.AgeGroup, Date.Month  Employee.Bad Hires YoY % Change   \n",
      "3  BU.Region, BU.VP, Ethnicity.Ethnicity           Sum(Employee.BadHires)   \n",
      "4                                                                           \n",
      "5                      AgeGroup.AgeGroup       Employee.BadHire%ofActives   \n",
      "6                              BU.Region                                    \n",
      "7                                                                           \n",
      "\n",
      "                                             Filters  \n",
      "0  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "1  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "2  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "3  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "4  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "5  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "6  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "7  AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "=== Section: ReportSection4 ('New Hires Scorecard') ===\n",
      "  Section  Visual Index                  Type                  Tables  \\\n",
      "0                     0               textbox                           \n",
      "1                     1                slicer                      BU   \n",
      "2                     2             lineChart          Date, Employee   \n",
      "3                     3              pieChart        Employee, Gender   \n",
      "4                     4              pieChart       Employee, PayType   \n",
      "5                     5  clusteredColumnChart  AgeGroup, Employee, FP   \n",
      "\n",
      "                        Columns            Measures    Filters  \n",
      "0                                                    Date.Year  \n",
      "1                         BU.VP                      Date.Year  \n",
      "2                    Date.Month  Employee.New Hires  Date.Year  \n",
      "3                 Gender.Gender  Employee.New Hires  Date.Year  \n",
      "4               PayType.PayType  Employee.New Hires  Date.Year  \n",
      "5  AgeGroup.AgeGroup, FP.FPDesc  Employee.New Hires  Date.Year  \n"
     ]
    }
   ],
   "source": [
    " # Replace with your PBIX file path\n",
    "pbix_path = 'D:\\\\Project\\\\pbix\\\\Human Resources Sample PBIX.pbix'\n",
    "infile =\"D:\\\\Project\\\\pbix\\\\Layout.json\"\n",
    "\n",
    "main2(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# import json\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "# import json\n",
    "\n",
    "def unzip_pbix(pbix_path):\n",
    "    \"\"\"\n",
    "    Unzips a Power BI .pbix file to a temporary directory.\n",
    "\n",
    "    Args:\n",
    "        pbix_path (str): Path to the .pbix file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the temporary directory containing the extracted files.\n",
    "    \"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    with zipfile.ZipFile(pbix_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "    return temp_dir\n",
    "\n",
    "def find_layout_json(unzipped_dir):\n",
    "    \"\"\"\n",
    "    Finds the Layout file in the unzipped PBIX directory (case-insensitive), regardless of extension or subfolder.\n",
    "\n",
    "    Args:\n",
    "        unzipped_dir (str): Path to the directory with PBIX contents.\n",
    "\n",
    "    Returns:\n",
    "        str: Full path to the Layout JSON file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no Layout file is found.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(unzipped_dir):\n",
    "        for fname in files:\n",
    "            if fname.lower().startswith(\"layout\"):\n",
    "                layout_path = os.path.join(root, fname)\n",
    "                return layout_path\n",
    "    raise FileNotFoundError(\"Layout file not found in PBIX contents.\")\n",
    "\n",
    "def read_layout_json(layout_path):\n",
    "    \"\"\"\n",
    "    Reads and parses the Layout JSON file from PBIX contents.\n",
    "\n",
    "    Args:\n",
    "        layout_path (str): Path to the Layout JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed JSON content of the Layout file.\n",
    "    \"\"\"\n",
    "    with open(layout_path, 'rb') as f:\n",
    "        raw_bytes = f.read()\n",
    "    raw_str = raw_bytes.decode('utf-8', errors='replace').replace('\\x00', '').strip()\n",
    "    return json.loads(raw_str)\n",
    "\n",
    "def extract_alias_map(proto_query):\n",
    "    alias_map = {}\n",
    "    from_list = proto_query.get('From', [])\n",
    "    for entry in from_list:\n",
    "        alias = entry.get('Name')\n",
    "        entity = entry.get('Entity')\n",
    "        if alias and entity:\n",
    "            alias_map[alias] = entity\n",
    "    return alias_map\n",
    "\n",
    "def extract_alias_map(proto_query):\n",
    "    alias_map = {}\n",
    "    from_list = proto_query.get('From', [])\n",
    "    for entry in from_list:\n",
    "        alias = entry.get('Name')\n",
    "        entity = entry.get('Entity')\n",
    "        if alias and entity:\n",
    "            alias_map[alias] = entity\n",
    "    return alias_map\n",
    "\n",
    "def extract_fields(selects, alias_map):\n",
    "    columns = []\n",
    "    measures = []\n",
    "    tables = set()\n",
    "    if not isinstance(selects, list):\n",
    "        return columns, measures, tables\n",
    "    for sel in selects:\n",
    "        # Column reference\n",
    "        if 'Column' in sel:\n",
    "            col = sel['Column']\n",
    "            source = None\n",
    "            if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                source = col['Expression']['SourceRef'].get('Source')\n",
    "            column = col.get('Property')\n",
    "            full_table = alias_map.get(source, source)\n",
    "            if full_table and column:\n",
    "                columns.append(f\"{full_table}.{column}\")\n",
    "                tables.add(full_table)\n",
    "        # Measure reference\n",
    "        if 'Measure' in sel:\n",
    "            meas = sel['Measure']\n",
    "            source = None\n",
    "            if 'Expression' in meas and 'SourceRef' in meas['Expression']:\n",
    "                source = meas['Expression']['SourceRef'].get('Source')\n",
    "            measure = meas.get('Property')\n",
    "            full_table = alias_map.get(source, source)\n",
    "            if full_table and measure:\n",
    "                measures.append(f\"{full_table}.{measure}\")\n",
    "                tables.add(full_table)\n",
    "        # Aggregation reference\n",
    "        if 'Aggregation' in sel:\n",
    "            agg = sel['Aggregation']\n",
    "            function_map = {\n",
    "                0: 'Sum', 1: 'Count', 2: 'Min', 3: 'Max', 4: 'Average', 5: 'DistinctCount'\n",
    "            }\n",
    "            func_name = function_map.get(agg.get('Function'), 'Aggregation')\n",
    "            agg_expr = agg.get('Expression', {})\n",
    "            if 'Column' in agg_expr:\n",
    "                col = agg_expr['Column']\n",
    "                source = None\n",
    "                if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                    source = col['Expression']['SourceRef'].get('Source')\n",
    "                column = col.get('Property')\n",
    "                full_table = alias_map.get(source, source)\n",
    "                if full_table and column:\n",
    "                    measures.append(f\"{func_name}({full_table}.{column})\")\n",
    "                    tables.add(full_table)\n",
    "    return columns, measures, tables\n",
    "\n",
    "def extract_filter_columns(filters_json, alias_map):\n",
    "    filter_columns = []\n",
    "    if not filters_json:\n",
    "        return filter_columns\n",
    "    try:\n",
    "        filters = json.loads(filters_json)\n",
    "    except Exception:\n",
    "        return filter_columns\n",
    "    for f in filters:\n",
    "        expr = f.get('expression', {})\n",
    "        # Only handle column filters\n",
    "        if 'Column' in expr:\n",
    "            col = expr['Column']\n",
    "            entity = None\n",
    "            if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                entity = col['Expression']['SourceRef'].get('Entity')\n",
    "            elif 'SourceRef' in col:\n",
    "                entity = col['SourceRef'].get('Entity')\n",
    "            column = col.get('Property')\n",
    "            if not entity:\n",
    "                # Try to get Source and map to Entity\n",
    "                source = None\n",
    "                if 'Expression' in col and 'SourceRef' in col['Expression']:\n",
    "                    source = col['Expression']['SourceRef'].get('Source')\n",
    "                elif 'SourceRef' in col:\n",
    "                    source = col['SourceRef'].get('Source')\n",
    "                entity = alias_map.get(source, source)\n",
    "            if entity and column:\n",
    "                filter_columns.append(f\"{entity}.{column}\")\n",
    "    return filter_columns\n",
    "\n",
    "def extract_all_visuals(layout):\n",
    "    visuals_all = []\n",
    "    for section in layout.get('sections', []):\n",
    "        section_name = section.get('name', '')\n",
    "        section_display = section.get('displayName', '')\n",
    "        section_filters = section.get('filters')\n",
    "        # Try alias map from first visual (if any)\n",
    "        alias_map = {}\n",
    "        if section.get('visualContainers'):\n",
    "            first_visual = section['visualContainers'][0]\n",
    "            config_str = first_visual.get('config')\n",
    "            try:\n",
    "                config = json.loads(config_str)\n",
    "                proto_query = config.get('singleVisual', {}).get('prototypeQuery', {})\n",
    "                alias_map = extract_alias_map(proto_query)\n",
    "            except Exception:\n",
    "                pass\n",
    "        section_filter_columns = extract_filter_columns(section_filters, alias_map)\n",
    "        for idx, visual in enumerate(section.get('visualContainers', [])):\n",
    "            config_str = visual.get('config')\n",
    "            try:\n",
    "                config = json.loads(config_str)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            visual_type = config.get('singleVisual', {}).get('visualType')\n",
    "            proto_query = config.get('singleVisual', {}).get('prototypeQuery', {})\n",
    "            local_alias_map = extract_alias_map(proto_query)\n",
    "            alias_map_used = local_alias_map if local_alias_map else alias_map\n",
    "            selects = proto_query.get('Select', [])\n",
    "            columns, measures, tables = extract_fields(selects, alias_map_used)\n",
    "            visual_filters = visual.get('filters')\n",
    "            visual_filter_columns = extract_filter_columns(visual_filters, alias_map_used)\n",
    "            combined_filters = sorted(list(set(section_filter_columns + visual_filter_columns)))\n",
    "            visuals_all.append({\n",
    "                'Section': section_name,\n",
    "                'Section Display': section_display,\n",
    "                'Visual Index': idx,\n",
    "                'Type': visual_type,\n",
    "                'Tables': ', '.join(sorted(list(tables))),\n",
    "                'Columns': ', '.join(sorted(columns)),\n",
    "                'Measures': ', '.join(sorted(measures)),\n",
    "                'Filters': ', '.join(combined_filters)\n",
    "            })\n",
    "    return visuals_all\n",
    "\n",
    "def pbix_layout_to_df(layout_path):\n",
    "    with open(layout_path, 'rb') as f:\n",
    "        raw_bytes = f.read()\n",
    "    raw = raw_bytes.decode('utf-8', errors='replace').replace('\\x00', '').strip()\n",
    "    layout = json.loads(raw)\n",
    "    visuals = extract_all_visuals(layout)\n",
    "    df = pd.DataFrame(visuals)\n",
    "    return df\n",
    "\n",
    "def explode_visuals_df(df):\n",
    "    # Split comma fields into lists, then explode\n",
    "    df1 = df.copy()\n",
    "    # Ensure empty strings become empty lists\n",
    "    for col in [\"Tables\", \"Columns\", \"Measures\", \"Filters\"]:\n",
    "        df1[col] = df1[col].apply(lambda x: [i.strip() for i in x.split(\",\")] if x else [])\n",
    "    # Explode Columns\n",
    "    cols_df = df1.explode(\"Columns\")\n",
    "    cols_df = cols_df[cols_df[\"Columns\"] != \"\"]\n",
    "    cols_df[\"iscolumn/ismeasure\"] = \"iscolumn\"\n",
    "    cols_df[\"Columns/Measures\"] = cols_df[\"Columns\"]\n",
    "    # Explode Measures\n",
    "    meas_df = df1.explode(\"Measures\")\n",
    "    meas_df = meas_df[meas_df[\"Measures\"] != \"\"]\n",
    "    meas_df[\"iscolumn/ismeasure\"] = \"ismeasure\"\n",
    "    meas_df[\"Columns/Measures\"] = meas_df[\"Measures\"]\n",
    "    # Combine\n",
    "    out_df = pd.concat([cols_df, meas_df], ignore_index=True)\n",
    "    # Explode Filters (optional: keep all filters, or join them with visual)\n",
    "    out_df = out_df.explode(\"Filters\")\n",
    "    # Clean up columns\n",
    "    out_df = out_df[[\"Section\", \"Section Display\", \"Visual Index\", \"Type\", \"Tables\", \"iscolumn/ismeasure\", \"Columns/Measures\", \"Filters\"]]\n",
    "    return out_df\n",
    "\n",
    "def explode_df_one_table_per_row(df):\n",
    "    rows = []\n",
    "    for idx, row in df.iterrows():\n",
    "        section = row.get(\"Section\", \"\")\n",
    "        section_display = row.get(\"Section Display\", \"\")\n",
    "        visual_idx = row.get(\"Visual Index\", \"\")\n",
    "        vtype = row.get(\"Type\", \"\")\n",
    "        filters = [f.strip() for f in str(row.get(\"Filters\", \"\")).split(\",\") if f.strip()]\n",
    "        \n",
    "        # Explode columns\n",
    "        for col in [c.strip() for c in str(row.get(\"Columns\", \"\")).split(\",\") if c.strip()]:\n",
    "            # Table is whatever is before the dot\n",
    "            table = col.split(\".\", 1)[0] if \".\" in col else \"\"\n",
    "            rows.append({\n",
    "                \"Section\": section,\n",
    "                \"Section Display\": section_display,\n",
    "                \"Visual Index\": visual_idx,\n",
    "                \"Type\": vtype,\n",
    "                \"Tables\": table,\n",
    "                \"iscolumn/ismeasure\": \"iscolumn\",\n",
    "                \"Columns/Measures\": col,\n",
    "                \"Filters\": \", \".join(filters)\n",
    "            })\n",
    "        # Explode measures\n",
    "        for meas in [m.strip() for m in str(row.get(\"Measures\", \"\")).split(\",\") if m.strip()]:\n",
    "            # Table is whatever is before the dot (for Employee.New Hires) or inside parenthesis (for Sum(Employee.BadHires))\n",
    "            # Handle both cases\n",
    "            table = \"\"\n",
    "            if \".\" in meas:\n",
    "                # Format like Employee.New Hires or Sum(Employee.BadHires)\n",
    "                if \"(\" in meas and \")\" in meas:\n",
    "                    # Find table inside parenthesis\n",
    "                    import re\n",
    "                    m = re.search(r\"\\(([^.]+)\\.[^)]+\\)\", meas)\n",
    "                    table = m.group(1) if m else \"\"\n",
    "                else:\n",
    "                    # Just split before dot\n",
    "                    table = meas.split(\".\", 1)[0]\n",
    "            rows.append({\n",
    "                \"Section\": section,\n",
    "                \"Section Display\": section_display,\n",
    "                \"Visual Index\": visual_idx,\n",
    "                \"Type\": vtype,\n",
    "                \"Tables\": table,\n",
    "                \"iscolumn/ismeasure\": \"ismeasure\",\n",
    "                \"Columns/Measures\": meas,\n",
    "                \"Filters\": \", \".join(filters)\n",
    "            })\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    return out_df\n",
    "\n",
    "def explode_df_one_table_per_row2(df, pbix_filename):\n",
    "    rows = []\n",
    "    for idx, row in df.iterrows():\n",
    "        section = row.get(\"Section\", \"\")\n",
    "        section_display = row.get(\"Section Display\", \"\")\n",
    "        visual_idx = row.get(\"Visual Index\", \"\")\n",
    "        vtype = row.get(\"Type\", \"\")\n",
    "        filters = [f.strip() for f in str(row.get(\"Filters\", \"\")).split(\",\") if f.strip()]\n",
    "        \n",
    "        # Explode columns\n",
    "        for col in [c.strip() for c in str(row.get(\"Columns\", \"\")).split(\",\") if c.strip()]:\n",
    "            table = col.split(\".\", 1)[0] if \".\" in col else \"\"\n",
    "            rows.append({\n",
    "                \"PBIX File\": pbix_filename,\n",
    "                \"Section\": section,\n",
    "                \"Section Display\": section_display,\n",
    "                \"Visual Index\": visual_idx,\n",
    "                \"Type\": vtype,\n",
    "                \"Tables\": table,\n",
    "                \"iscolumn/ismeasure\": \"iscolumn\",\n",
    "                \"Columns/Measures\": col,\n",
    "                \"Filters\": \", \".join(filters)\n",
    "            })\n",
    "        # Explode measures\n",
    "        for meas in [m.strip() for m in str(row.get(\"Measures\", \"\")).split(\",\") if m.strip()]:\n",
    "            table = \"\"\n",
    "            if \".\" in meas:\n",
    "                if \"(\" in meas and \")\" in meas:\n",
    "                    import re\n",
    "                    m = re.search(r\"\\(([^.]+)\\.[^)]+\\)\", meas)\n",
    "                    table = m.group(1) if m else \"\"\n",
    "                else:\n",
    "                    table = meas.split(\".\", 1)[0]\n",
    "            rows.append({\n",
    "                \"PBIX File\": pbix_filename,\n",
    "                \"Section\": section,\n",
    "                \"Section Display\": section_display,\n",
    "                \"Visual Index\": visual_idx,\n",
    "                \"Type\": vtype,\n",
    "                \"Tables\": table,\n",
    "                \"iscolumn/ismeasure\": \"ismeasure\",\n",
    "                \"Columns/Measures\": meas,\n",
    "                \"Filters\": \", \".join(filters)\n",
    "            })\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    return out_df\n",
    "\n",
    "def pbix_to_exploded_df(pbix_path):\n",
    "    pbix_filename = os.path.basename(pbix_path)\n",
    "    temp_dir = unzip_pbix(pbix_path)\n",
    "    layout_path = find_layout_json(temp_dir)\n",
    "    layout_json = read_layout_json(layout_path)\n",
    "    # Use your extraction function here\n",
    "    visuals_df = pbix_layout_to_df(layout_path)\n",
    "    exploded_df = explode_df_one_table_per_row2(visuals_df, pbix_filename)\n",
    "    # Optionally, clean up temp_dir if needed\n",
    "    return exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PBIX File         Section      Section Display  \\\n",
      "0   Human Resources Sample PBIX.pbix  ReportSection2            New Hires   \n",
      "1   Human Resources Sample PBIX.pbix  ReportSection2            New Hires   \n",
      "2   Human Resources Sample PBIX.pbix  ReportSection2            New Hires   \n",
      "3   Human Resources Sample PBIX.pbix  ReportSection2            New Hires   \n",
      "4   Human Resources Sample PBIX.pbix  ReportSection2            New Hires   \n",
      "..                               ...             ...                  ...   \n",
      "60  Human Resources Sample PBIX.pbix  ReportSection4  New Hires Scorecard   \n",
      "61  Human Resources Sample PBIX.pbix  ReportSection4  New Hires Scorecard   \n",
      "62  Human Resources Sample PBIX.pbix  ReportSection4  New Hires Scorecard   \n",
      "63  Human Resources Sample PBIX.pbix  ReportSection4  New Hires Scorecard   \n",
      "64  Human Resources Sample PBIX.pbix  ReportSection4  New Hires Scorecard   \n",
      "\n",
      "    Visual Index                           Type    Tables iscolumn/ismeasure  \\\n",
      "0              1                      lineChart      Date           iscolumn   \n",
      "1              1                      lineChart        FP           iscolumn   \n",
      "2              1                      lineChart  Employee          ismeasure   \n",
      "3              2  lineClusteredColumnComboChart      Date           iscolumn   \n",
      "4              2  lineClusteredColumnComboChart  Employee          ismeasure   \n",
      "..           ...                            ...       ...                ...   \n",
      "60             4                       pieChart   PayType           iscolumn   \n",
      "61             4                       pieChart  Employee          ismeasure   \n",
      "62             5           clusteredColumnChart  AgeGroup           iscolumn   \n",
      "63             5           clusteredColumnChart        FP           iscolumn   \n",
      "64             5           clusteredColumnChart  Employee          ismeasure   \n",
      "\n",
      "                 Columns/Measures  \\\n",
      "0                      Date.Month   \n",
      "1                       FP.FPDesc   \n",
      "2              Employee.New Hires   \n",
      "3                      Date.Month   \n",
      "4   Employee.Actives YoY % Change   \n",
      "..                            ...   \n",
      "60                PayType.PayType   \n",
      "61             Employee.New Hires   \n",
      "62              AgeGroup.AgeGroup   \n",
      "63                      FP.FPDesc   \n",
      "64             Employee.New Hires   \n",
      "\n",
      "                                              Filters  \n",
      "0   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "1   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "2   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "3   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "4   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "..                                                ...  \n",
      "60                                          Date.Year  \n",
      "61                                          Date.Year  \n",
      "62                                          Date.Year  \n",
      "63                                          Date.Year  \n",
      "64                                          Date.Year  \n",
      "\n",
      "[65 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "pbix_file =  'D:\\\\Project\\\\pbix\\\\Human Resources Sample PBIX.pbix'\n",
    "outfile =\"D:\\\\Project\\\\pbix\\\\Layout5.csv\"\n",
    "df = pbix_to_exploded_df(pbix_file)\n",
    "print(df)\n",
    "df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      PBIX File         Section      Section Display  \\\n",
      "0   D:\\Project\\pbix\\Layout.json  ReportSection2            New Hires   \n",
      "1   D:\\Project\\pbix\\Layout.json  ReportSection2            New Hires   \n",
      "2   D:\\Project\\pbix\\Layout.json  ReportSection2            New Hires   \n",
      "3   D:\\Project\\pbix\\Layout.json  ReportSection2            New Hires   \n",
      "4   D:\\Project\\pbix\\Layout.json  ReportSection2            New Hires   \n",
      "..                          ...             ...                  ...   \n",
      "60  D:\\Project\\pbix\\Layout.json  ReportSection4  New Hires Scorecard   \n",
      "61  D:\\Project\\pbix\\Layout.json  ReportSection4  New Hires Scorecard   \n",
      "62  D:\\Project\\pbix\\Layout.json  ReportSection4  New Hires Scorecard   \n",
      "63  D:\\Project\\pbix\\Layout.json  ReportSection4  New Hires Scorecard   \n",
      "64  D:\\Project\\pbix\\Layout.json  ReportSection4  New Hires Scorecard   \n",
      "\n",
      "    Visual Index                           Type    Tables iscolumn/ismeasure  \\\n",
      "0              1                      lineChart      Date           iscolumn   \n",
      "1              1                      lineChart        FP           iscolumn   \n",
      "2              1                      lineChart  Employee          ismeasure   \n",
      "3              2  lineClusteredColumnComboChart      Date           iscolumn   \n",
      "4              2  lineClusteredColumnComboChart  Employee          ismeasure   \n",
      "..           ...                            ...       ...                ...   \n",
      "60             4                       pieChart   PayType           iscolumn   \n",
      "61             4                       pieChart  Employee          ismeasure   \n",
      "62             5           clusteredColumnChart  AgeGroup           iscolumn   \n",
      "63             5           clusteredColumnChart        FP           iscolumn   \n",
      "64             5           clusteredColumnChart  Employee          ismeasure   \n",
      "\n",
      "                 Columns/Measures  \\\n",
      "0                      Date.Month   \n",
      "1                       FP.FPDesc   \n",
      "2              Employee.New Hires   \n",
      "3                      Date.Month   \n",
      "4   Employee.Actives YoY % Change   \n",
      "..                            ...   \n",
      "60                PayType.PayType   \n",
      "61             Employee.New Hires   \n",
      "62              AgeGroup.AgeGroup   \n",
      "63                      FP.FPDesc   \n",
      "64             Employee.New Hires   \n",
      "\n",
      "                                              Filters  \n",
      "0   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "1   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "2   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "3   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "4   AgeGroup.AgeGroup, BU.Region, BU.VP, Date.Mont...  \n",
      "..                                                ...  \n",
      "60                                          Date.Year  \n",
      "61                                          Date.Year  \n",
      "62                                          Date.Year  \n",
      "63                                          Date.Year  \n",
      "64                                          Date.Year  \n",
      "\n",
      "[65 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Usage:\n",
    "# infile =\"D:\\\\Project\\\\pbix\\\\Layout.json\"\n",
    "\n",
    "# df = pbix_layout_to_df(infile)\n",
    "# # exploded_df = explode_visuals_df(df)\n",
    "# exploded_df = explode_df_one_table_per_row2(df,infile)\n",
    "# print(exploded_df)\n",
    "# exploded_df.to_csv(outfile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
